model:
  dim_freq      : 192
  timestep      : 108
  hidden_size   : 128
  dim_k         : 128
  dim_v         : 128
  n_heads       : 4
  n_layers      : 8
  input_dropout : 0.2
  layer_dropout : 0.2
  attn_dropout  : 0.2
  act_dropout   : 0.2
  n_chords      : 170

experiment:
  batch_size    : 128
  max_epochs    : 200
  learning_rate : 0.0001
  reduce_factor : 0.8
  min_lr        : 0.000001